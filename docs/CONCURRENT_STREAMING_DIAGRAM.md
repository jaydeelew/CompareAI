# Concurrent Streaming Architecture Diagram

## Before: Sequential Processing âŒ

```
User Request â†’ Backend
                  â†“
            Start Model 1
                  â†“
            â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ (5s)
                  â†“
            Done Model 1
                  â†“
            Start Model 2
                  â†“
            â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ (5s)
                  â†“
            Done Model 2
                  â†“
            Start Model 3
                  â†“
            â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ (5s)
                  â†“
            Done Model 3
                  â†“
Total Time: 15 seconds
```

## After: Concurrent Processing âœ…

```
User Request â†’ Backend
                  â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”
         â†“        â†“        â†“
    Start M1  Start M2  Start M3
         â†“        â†“        â†“
    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
         â†“        â†“        â†“
    Done M1  Done M2  Done M3
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â†“
Total Time: ~5 seconds (6-9x faster!)
```

## Technical Flow

### Sequential (Old)

```
Time â†’
0s:  [Model 1 starts........................]
5s:                                         [Model 1 done] [Model 2 starts........................]
10s:                                                                                              [Model 2 done] [Model 3 starts........................]
15s:                                                                                                                                                       [Model 3 done]
```

### Concurrent (New)

```
Time â†’
0s:  [Model 1 starts..........]
     [Model 2 starts...............]
     [Model 3 starts.......................]
5s:                           [M1 done]
6s:                                  [M2 done]
7s:                                              [M3 done]
```

## Chunk Streaming Visualization

### Sequential

```
Chunks received:
M1: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  (chunks 1-40, all from Model 1)
M2: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  (chunks 41-80, all from Model 2)
M3: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  (chunks 81-120, all from Model 3)
```

### Concurrent

```
Chunks received (interleaved):
Mixed: â–ˆ1â–ˆ2â–ˆ3â–ˆ1â–ˆ2â–ˆ1â–ˆ3â–ˆ2â–ˆ3â–ˆ1â–ˆ3â–ˆ2â–ˆ1â–ˆ2â–ˆ3â–ˆ1â–ˆ3â–ˆ2...
       Model 1 chunks: â–“
       Model 2 chunks: â–’
       Model 3 chunks: â–‘
```

## System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Frontend (React)                  â”‚
â”‚  - Receives SSE events from all models             â”‚
â”‚  - Displays chunks as they arrive (interleaved)     â”‚
â”‚  - Tracks individual model start/end times          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†• SSE (Server-Sent Events)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Backend (FastAPI + asyncio)             â”‚
â”‚                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚      async def generate_stream()           â”‚    â”‚
â”‚  â”‚                                             â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚    â”‚
â”‚  â”‚  â”‚   asyncio.Queue (chunk_queue)       â”‚  â”‚    â”‚
â”‚  â”‚  â”‚   - Collects chunks from all models â”‚  â”‚    â”‚
â”‚  â”‚  â”‚   - Thread-safe communication       â”‚  â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚    â”‚
â”‚  â”‚         â†‘           â†‘           â†‘          â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”´â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”   â”‚    â”‚
â”‚  â”‚  â”‚  Task 1   â”‚ â”‚ Task 2 â”‚ â”‚  Task 3  â”‚   â”‚    â”‚
â”‚  â”‚  â”‚  Model 1  â”‚ â”‚ Model 2â”‚ â”‚  Model 3 â”‚   â”‚    â”‚
â”‚  â”‚  â”‚ (thread)  â”‚ â”‚(thread)â”‚ â”‚ (thread) â”‚   â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†• HTTPS
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              OpenRouter API                          â”‚
â”‚  - Receives 3 concurrent requests                   â”‚
â”‚  - Routes to Claude, GPT-4, Gemini, etc.           â”‚
â”‚  - Streams responses back independently             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Code Flow

### 1. Start Phase (Concurrent)

```python
# All models receive start events simultaneously
for model_id in req.models:
    yield f"data: {{'model': '{model_id}', 'type': 'start'}}\n\n"

# Start timestamp: 2025-10-26T10:00:00.000Z (same for all)
```

### 2. Streaming Phase (Concurrent)

```python
# Tasks run in parallel, push to queue
async def stream_single_model(model_id):
    # Runs in thread pool
    for chunk in call_openrouter_streaming(...):
        await chunk_queue.put({
            'model': model_id,
            'content': chunk
        })

# Main loop yields chunks as they arrive
while tasks_pending:
    chunk = await chunk_queue.get()
    yield f"data: {{'model': ..., 'type': 'chunk', 'content': ...}}\n\n"
```

### 3. Completion Phase (Staggered)

```python
# Each model finishes independently
# Model 1 done: 2025-10-26T10:00:05.123Z
yield f"data: {{'model': 'model1', 'type': 'done'}}\n\n"

# Model 2 done: 2025-10-26T10:00:06.456Z
yield f"data: {{'model': 'model2', 'type': 'done'}}\n\n"

# Model 3 done: 2025-10-26T10:00:07.789Z
yield f"data: {{'model': 'model3', 'type': 'done'}}\n\n"
```

## Benefits Summary

| Aspect          | Sequential    | Concurrent   | Improvement          |
| --------------- | ------------- | ------------ | -------------------- |
| Start times     | Staggered     | Simultaneous | âœ… Better UX         |
| Total time      | Sum of all    | Max of all   | âœ… 3-9x faster       |
| Chunk delivery  | One at a time | Interleaved  | âœ… More responsive   |
| Error isolation | Blocks others | Independent  | âœ… More robust       |
| Resource usage  | Underutilized | Optimal      | âœ… Better efficiency |

## Real-World Example

**User selects 3 models**: Claude 3.5 Sonnet, GPT-4o-mini, Gemini 2.0

### Sequential (Old)

```
00:00 - Start Claude
00:05 - Claude done, start GPT-4
00:10 - GPT-4 done, start Gemini
00:15 - Gemini done
      - User waits 15 seconds for all responses
```

### Concurrent (New)

```
00:00 - Start all 3 models
00:05 - Claude done (fast model)
00:06 - GPT-4 done (medium speed)
00:07 - Gemini done (slowest)
      - User waits 7 seconds for all responses
      - 2.1x faster! ğŸ‰
```

---

**Visual Summary**: Instead of waiting in line at 3 sequential checkouts, all 3 checkouts process simultaneously!
